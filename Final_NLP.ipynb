{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ResearchReader"
      ],
      "metadata": {
        "id": "y0LeTJDMDE-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ROLL NO :\n",
        "C236\n",
        "C258\n",
        "C275"
      ],
      "metadata": {
        "id": "KOJUlQfcCzPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiL3t-QzE4g_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac6c80d-f9e6-41f2-f6f4-1cd28702ef83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0269b974",
        "outputId": "73841e98-0ad2-4c42-f8c4-44b495895ee1"
      },
      "source": [
        "!pip install PyPDF2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import re\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "\n",
        "def load_spacy_model(model_name='en_core_web_lg'):\n",
        "    \"\"\"Loads a spaCy model, downloading it if not found.\"\"\"\n",
        "    try:\n",
        "        nlp = spacy.load(model_name)\n",
        "    except OSError:\n",
        "        print(f\"Downloading spaCy model '{model_name}'. This may take a moment.\")\n",
        "        from spacy.cli import download\n",
        "        download(model_name)\n",
        "        nlp = spacy.load(model_name)\n",
        "    return nlp\n",
        "\n",
        "def extract_pdf_text(filepath):\n",
        "    \"\"\"Extracts raw text from a given PDF file.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'rb') as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            text_parts = [page.extract_text() for page in reader.pages if page.extract_text()]\n",
        "        full_text = \" \".join(text_parts)\n",
        "        return re.sub(r'\\s+', ' ', full_text)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: The file '{filepath}' was not found.\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while reading the PDF: {e}\")\n",
        "        return None\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculates the cosine similarity between two vectors.\"\"\"\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "def generate_summary(doc, num_sentences=3):\n",
        "    \"\"\"Generates a summary by finding sentences most similar to the document's overall meaning.\"\"\"\n",
        "    # Create a document vector from meaningful words\n",
        "    keywords = [token.vector for token in doc if not token.is_stop and not token.is_punct and token.has_vector]\n",
        "    if not keywords:\n",
        "        return \"Document is too short to summarize.\", []\n",
        "\n",
        "    doc_vector = np.mean(keywords, axis=0)\n",
        "\n",
        "    # Score sentences based on similarity to the document vector\n",
        "    sentences = list(doc.sents)\n",
        "    sentence_scores = {sent: cosine_similarity(sent.vector, doc_vector) for sent in sentences if sent.has_vector}\n",
        "\n",
        "    # Sort and select the top sentences\n",
        "    top_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]\n",
        "    summary = \" \".join([sent.text for sent in top_sentences])\n",
        "\n",
        "    return summary, sentences\n",
        "\n",
        "def find_answer(question_doc, sentences, relevance_threshold=0.6):\n",
        "    \"\"\"Finds the best sentence in a document to answer a question.\"\"\"\n",
        "    if not question_doc.has_vector:\n",
        "        return \"Could not understand the question.\"\n",
        "\n",
        "    best_sentence = None\n",
        "    max_sim = -1.0\n",
        "\n",
        "    for sentence in sentences:\n",
        "        if sentence.has_vector:\n",
        "            sim = cosine_similarity(question_doc.vector, sentence.vector)\n",
        "            if sim > max_sim:\n",
        "                max_sim = sim\n",
        "                best_sentence = sentence\n",
        "\n",
        "    if max_sim > relevance_threshold and best_sentence:\n",
        "        return best_sentence.text\n",
        "    else:\n",
        "        return \"No confident answer found in the document.\"\n",
        "\n",
        "def extract_section(text, section_title):\n",
        "    \"\"\"Extracts a specific section by its title using a flexible regex pattern.\"\"\"\n",
        "    # Pattern to find a heading, ignoring case and allowing for numbering\n",
        "    pattern = re.compile(\n",
        "        r'(?i)^\\s*(\\d+\\.?\\s*)?' + re.escape(section_title) + r'\\s*?\\n(.*?)(?=\\n\\s*\\d+\\.?\\s+[A-Z]|\\n\\s*[A-Z]{2,})',\n",
        "        re.DOTALL | re.MULTILINE\n",
        "    )\n",
        "    match = pattern.search(text)\n",
        "    return match.group(2).strip() if match else f\"Section '{section_title}' not found.\"\n",
        "\n",
        "def display_menu():\n",
        "    \"\"\"Prints the main menu options to the console.\"\"\"\n",
        "    print(\"\\n-- Menu --\")\n",
        "    print(\"1. Show Summary\")\n",
        "    print(\"2. Ask a Question\")\n",
        "    print(\"3. Extract Section (e.g., Introduction, Methods)\")\n",
        "    print(\"4. Exit\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main application loop for the research paper analyzer.\"\"\"\n",
        "    nlp = load_spacy_model()\n",
        "\n",
        "    pdf_path = input(\"Enter the path to the research paper PDF: \")\n",
        "    raw_text = extract_pdf_text(pdf_path)\n",
        "    if not raw_text:\n",
        "        return\n",
        "\n",
        "    print(\"Processing document...\")\n",
        "    doc = nlp(raw_text)\n",
        "\n",
        "    try:\n",
        "        summary_length = int(input(\"Enter number of sentences for summary: \"))\n",
        "    except ValueError:\n",
        "        print(\"Invalid number. Defaulting to 3 sentences.\")\n",
        "        summary_length = 3\n",
        "\n",
        "    summary, sentences = generate_summary(doc, summary_length)\n",
        "    print(\"\\n--- Document Summary ---\")\n",
        "    print(summary)\n",
        "\n",
        "    while True:\n",
        "        display_menu()\n",
        "        choice = input(\"Your choice (1-4): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            print(\"\\n--- Document Summary ---\")\n",
        "            print(summary)\n",
        "        elif choice == '2':\n",
        "            question = input(\"Your question: \")\n",
        "            question_doc = nlp(question)\n",
        "            answer = find_answer(question_doc, sentences)\n",
        "            print(f\"\\nAnswer: {answer}\")\n",
        "        elif choice == '3':\n",
        "            section_name = input(\"Enter section title to extract: \")\n",
        "            section_content = extract_section(raw_text, section_name.strip())\n",
        "            print(f\"\\n--- Extracted: {section_name.title()} ---\")\n",
        "            print(section_content)\n",
        "        elif choice == '4':\n",
        "            print(\"Exiting.\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please enter a number from 1 to 4.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82wdaHkL88y8",
        "outputId": "d5af4868-71cd-4724-be5a-24b610f11ec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to the research paper PDF: /content/Introduction of Research Papers.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2._reader:incorrect startxref pointer(1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing document...\n",
            "Enter number of sentences for summary: 23\n",
            "\n",
            "--- Document Summary ---\n",
            "[Stating Research Focus and Objectives] This study thus fits within existing literature concerning the foundations and outcomes of indigenous forest and wildlife management. Education Most educational research papers involve critical analysis of teaching methods and pedagogical theory as they apply to real-life teaching situations. Most social science introductions follow the same structure outlined in this resource. Introductions for medical research papers should first broadly review relevant background information on the research topic, then narrow to a focused research question(s), thesis statement, and study objective. [Stating Research Question] That is, have the land-based values and practices of indigenous peoples in Wisconsin led to significantly dif ferent ecological Introduction Section for Research Papers, Winter 2023.6of8 conditions on their forestlands relative to neighboring lands? [Narrowing of the Topic] The relationships between indigenous land tenure and biological diversity is a challenging area of research, but several studies suggest that indigenous peoples’ place-based values, institutions, and practices help promote biodiversity . Engineering papers are often highly technical and should include a brief history of the research topic or study being undertaken. Humanities These types of research papers often allow for more creativity in writing but should still retain a structured academic approach. This article uses quantitative data and statistics to provide background information and context, but it also ties in the human experience by mentioning the health impacts and cost of snakebites. The social sciences rely heavily on existing literature and are often founded on primary and secondary research. The introduction should include background information on related experiments, data sets, explanations of technical terms, and a statement about the significance of your study . Most social sciences also require extensive qualitative data analysis, as well as accuracy and honesty in presenting information. The literature review , however , critically evaluates the existing research in greater detail, summarizing and synthesizing important articles. Open your selected journal, and input key terms that interest you to identify three related research articles. Engineering Engineering research papers often involve tools similar to that of business writing. However , beyond a handful of studies looking at biodiversity and land use change, few researchers have looked at the broader ecological outcomes of indigenous land tenure. While the introduction often includes a brief overview of the important research on your topic, it should not be overly specific when discussing the literature. Sample of a Qualitative Introduction with Annotations This next sample involves qualitative data, which is descriptive data involving language, themes, and ideas about the human experience. Although commercial and ecological forestry best-practices are utilized in tribal forestry programs, indigenous communities’ own knowledge systems and values have a strong influence. Start by broadly introducing the topic, then provide general background information, narrowing to specific background research, and finally a focused research question, hypothesis, or thesis statement (general to specific). Notice the author ’s use of general to specific as they guided the reader to their focused research hypothesis. [Specific Background Context] Indigenous peoples in Wisconsin manage forestlands and wildlife by mer ging professional standards of forestry and wildlife practice with their own culturally specific traditional ecological knowledge and land-based values. These observations will further guide you in writing strong introductions that adhere to the standards of your academic discipline.\n",
            "\n",
            "-- Menu --\n",
            "1. Show Summary\n",
            "2. Ask a Question\n",
            "3. Extract Section (e.g., Introduction, Methods)\n",
            "4. Exit\n",
            "Your choice (1-4): 2\n",
            "Your question: with what is climate change in North America is associated with? \n",
            "\n",
            "Answer: Likewise, climate change in North America is associated with changing distribution of venomous species that may lead to increased human morbidity [12,15,16].\n",
            "\n",
            "-- Menu --\n",
            "1. Show Summary\n",
            "2. Ask a Question\n",
            "3. Extract Section (e.g., Introduction, Methods)\n",
            "4. Exit\n",
            "Your choice (1-4): 4\n",
            "Exiting.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}